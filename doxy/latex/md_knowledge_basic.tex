



\paragraph*{服务器并发模式分析}

{\bfseries 1. 单进程多线程模式}

通过在单进程内创建线程池，使工作线程异步并行地为客户的请求服务。

{\bfseries 优点：}

（1）工作线程之间数据共享方便（全局、静态变量）。

（2）线程的上下文切换开销较小（不切换地址空间，不刷新 T\+L\+B，只修改部分 C\+PU 寄存器），善于处理高并发。

（3）线程创建速度较快。

{\bfseries 缺点：}

（1）一个线程挂了，其他线程也就挂了。（虽然能写守护进程来重启，但是会有宕机期。）

（2）编程时需要考虑资源的同步问题，稍显复杂。

{\bfseries 2. 多进程单线程模式}

{\bfseries 优点：}

（1）一个进程崩溃可以被 master 重启，并不会使整个服务器挂掉。因此 master 安全隔离了工作进程。

（2）数据隔离和错误隔离。

（3）编程相对简单，通常不同考虑资源同步的问题。

{\bfseries 缺点：}

（1）进程切换开销大，对高并发的处理能力不如多线程模式。

{\bfseries 3. 多进程多线程模式}

在每个子进程内开多个线程。在支持高并发的情况下，避免了单进程多线程的宕机问题。

{\bfseries 4. Pink server 的模式}

目前的 Pink 为单进程多线程模式（更像单进程版的 Apache event M\+PM 模式）。实现这个模式一是为了熟悉多线程编程、资源同步方式，二是觉得从多线程到多进程的过度相对容易。（下一个 server 实现多进程。） 



\paragraph*{主流的 Web 服务器分析}

{\bfseries 1. Apache}

Apache 有三种稳定的 M\+P\+M（multi-\/processing module），即多进程处理模块。分别是 prefork、worker和 event。

（1）prefork（\+Linux 下的默认模式）

很古老但十分稳定。通过预先 fork 一些子进程等待请求。一个子进程一个线程，处理一个请求。

优点：不需要考虑线程安全问题。成熟稳定。

缺点：子进程数量有上限，不能 handle 高并发的情况。进程的内存开销大。

（2）worker

在 prefork 的基础上，每个子进程中创建多个线程。（这里使用多进程是为了服务器的稳定性。）

优点：高并发下比 prefork 更优秀，占据更少内存。

缺点：由于用了多线程，则需要考虑线程安全问题。

（3）event

把工作线程和连接分离开来，从而解决 keep-\/alive 连接总是占据一个工作线程的问题。以事件的形式触发线程。（基于 linux epoll）

优点：处理了 keep-\/alive 连接的情况。更高的并发量。事件驱动使得更适合于 IO 密集型服务。

缺点：对于 H\+T\+T\+PS 连接，仍然是类似 worker 模式，线程会一直被占用的。

{\bfseries 2. NginX}

参考1：https\+://www.jianshu.\+com/p/a253d21e4b16

参考2（阿里云天基blog）：http\+://tengine.taobao.\+org/book/\#id4

轻量级的异步非阻塞高性能 H\+T\+T\+P/ 反向代理 服务器。（也可以作为邮件服务器）

特点：

（1) 多进程，分为 master 和多个 worker 进程。

（2）每个进程单线程，因此省去了线程切换的开销，可以看成单线程循环处理一系列准备好的任务，十分高效。

（3）定时器处理方法：每次 epoll\+\_\+wait 的超时时间设置为最近要超时的定时器到现在的时间差。

伪代码： 
\begin{DoxyCode}
\textcolor{keywordflow}{while} (\textcolor{keyword}{true}) \{
    \textcolor{keywordflow}{for} t in run\_tasks:
        t.handler();
    update\_time(&now);
    timeout = ETERNITY;
    \textcolor{keywordflow}{for} t in wait\_tasks: \textcolor{comment}{/* sorted already */}
        \textcolor{keywordflow}{if} (t.time <= now) \{
            t.timeout\_handler();
        \} \textcolor{keywordflow}{else} \{
            timeout = t.time - now;
            \textcolor{keywordflow}{break};
        \}
    nevents = poll\_function(\hyperlink{pink__epoll_8cpp_a18bcd14e4d4cab5184d3b046754cd248}{events}, timeout);
    \textcolor{keywordflow}{for} i in nevents:
        task t;
        \textcolor{keywordflow}{if} (\hyperlink{pink__epoll_8cpp_a18bcd14e4d4cab5184d3b046754cd248}{events}[i].type == READ) \{
            t.handler = read\_handler;
        \} \textcolor{keywordflow}{else} \{ \textcolor{comment}{/* events[i].type == WRITE */}
            t.handler = write\_handler;
        \}
        run\_tasks\_add(t);
\}
\end{DoxyCode}


（4）解析 H\+T\+TP 请求报文中的 method 时，将四个字符转换成一个整型，然后一次比较以减少cpu的指令数。

优点：

（1）轻量级，比 apache 占用更少的内存资源。

（2）高度模块化的设计。

（3）性能强大，静态处理性能比 apache 高三倍以上。 



\paragraph*{H\+T\+TP 1.\+0、\+H\+T\+TP 1.\+1、\+H\+T\+TP 2.\+0}

参考1：https\+://www.cnblogs.\+com/heluan/p/8620312.html


\begin{DoxyEnumerate}
\item H\+T\+TP 1.\+0（1996)
\item H\+T\+TP 1.\+1（1999)
\end{DoxyEnumerate}

比 1.\+0 版本多了：

（1）$\ast$$\ast$缓存处理$\ast$$\ast$，在\+H\+T\+T\+P1.0中主要使用header里的\+If-\/\+Modified-\/\+Since,Expires来做为缓存判断的标准，\+H\+T\+T\+P1.1则引入了更多的缓存控制策略例如\+Entity tag，\+If-\/\+Unmodified-\/\+Since, If-\/\+Match, If-\/\+None-\/\+Match等更多可供选择的$\ast$$\ast$缓存头$\ast$$\ast$来控制缓存策略。

（2）$\ast$$\ast$带宽优化及网络连接的使用$\ast$$\ast$，\+H\+T\+T\+P1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且$\ast$$\ast$不支持断点续传$\ast$$\ast$功能，\+H\+T\+T\+P1.1则在请求头引入了$\ast$$\ast$range头域$\ast$$\ast$，它允许只请求资源的某个部分，即返回码是206（\+Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

（3）$\ast$$\ast$错误通知的管理$\ast$$\ast$，在\+H\+T\+T\+P1.1中新增了24个$\ast$$\ast$错误状态响应码$\ast$$\ast$，如409（\+Conflict）表示请求的资源与资源的当前状态发生冲突；410（\+Gone）表示服务器上的某个资源被永久性的删除。

（4）$\ast$$\ast$\+Host头处理$\ast$$\ast$，在\+H\+T\+T\+P1.0中认为每台服务器都绑定一个唯一的\+I\+P地址，因此，请求消息中的\+U\+R\+L并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（\+Multi-\/homed Web Servers），并且它们共享一个\+I\+P地址。\+H\+T\+T\+P1.1的请求消息和响应消息都应支持\+Host头域，且$\ast$$\ast$请求消息中如果没有\+Host头域会报告一个错误$\ast$$\ast$（400 Bad Request）。

（5）$\ast$$\ast$长连接$\ast$$\ast$，\+H\+T\+TP 1.\+1支持长连接（\+Persistent\+Connection）和请求的流水线（\+Pipelining）处理，在一个\+T\+C\+P连接上可以传送多个\+H\+T\+T\+P请求和响应，减少了建立和关闭连接的消耗和延迟，在\+H\+T\+T\+P1.1中默认开启$\ast$$\ast$\+Connection： keep-\/alive$\ast$$\ast$，一定程度上弥补了\+H\+T\+T\+P1.0每次请求都要创建连接的缺点。


\begin{DoxyEnumerate}
\item H\+T\+TP 2.\+0（2015）
\end{DoxyEnumerate}

基于 google 2012 年提出的 S\+P\+DY 设计的。

（1）$\ast$$\ast$新的二进制格式（\+Binary Format）$\ast$$\ast$，\+H\+T\+T\+P1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑\+H\+T\+T\+P2.0的协议解析决定采用二进制格式，实现方便且健壮。

（2）$\ast$$\ast$多路复用（\+Multi\+Plexing）$\ast$$\ast$，即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。({\bfseries More}\+: H\+T\+T\+P/2引入二进制数据帧和流的概念，其中帧对数据进行顺序标识，如下图所示，这样浏览器收到数据之后，就可以按照序列对数据进行合并，而不会出现合并后数据错乱的情况。)

（3）$\ast$$\ast$header压缩$\ast$$\ast$，如上文中所言，对前面提到过\+H\+T\+T\+P1.x的header带有大量信息，而且每次都要重复发送，\+H\+T\+T\+P2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。

（4）$\ast$$\ast$服务端推送（server push）$\ast$$\ast$，实现了类似\+S\+P\+D\+Y的功能：采用了\+S\+P\+D\+Y的网页，例如我的网页有一个sytle.css的请求，在客户端收到sytle.\+css数据的同时，服务端会将sytle.\+js的文件推送给客户端，当客户端再次尝试获取sytle.\+js时就可以直接从缓存中获取到，不用再发请求了。

{\bfseries 多路复用带来的优化：}

H\+T\+TP 性能优化的关键并不在于高带宽，而是低延迟。\+T\+CP 连接会随着时间进行自我「调谐」，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐则被称为 T\+CP 慢启动。由于这种原因，让原本就具有突发性和短时性的 H\+T\+TP 连接变的十分低效。 H\+T\+T\+P/2 通过让所有数据流共用同一个连接，可以更有效地使用 T\+CP 连接，让高带宽也能真正的服务于 H\+T\+TP 的性能提升。

 



\paragraph*{H\+T\+TP Web 服务器基础概念}



（1）建立连接

（2）接收请求（从网络中读取\+H\+T\+T\+P请求报文）

（3）处理请求（对请求报文进行解释，并采取行动）

（4）访问资源（访问报文中指定的资源）

（5）构建响应（创建带有正确首部的\+H\+T\+T\+P响应报文）

（6）发送响应（将响应回送给客户端）

（7）记录事务处理过程（将与已完成事务有关的内容记录在一个日志文件中） 